# -*- coding: utf-8 -*-
"""FED.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TRdRmKf5ABAK--GRoNcvZqcGp3ycmVxq
"""

!pip install keras keras_preprocessing

import os
import numpy as np
import pandas as pd
from tqdm.notebook import tqdm
from keras.utils import to_categorical
from keras_preprocessing.image import load_img, ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, BatchNormalization
from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from sklearn.preprocessing import LabelEncoder
import kagglehub

# Dataset Download
path = kagglehub.dataset_download("jonathanoheix/face-expression-recognition-dataset")
TRAIN_DIR = os.path.join(path, "images", "train")
TEST_DIR = os.path.join(path, "images", "validation")

# Dataset to DataFrame
def createdataframe(dir):
    image_paths, labels = [], []
    for label in os.listdir(dir):
        for image in os.listdir(os.path.join(dir, label)):
            image_paths.append(os.path.join(dir, label, image))
            labels.append(label)
    return image_paths, labels

train = pd.DataFrame()
train['image_paths'], train['labels'] = createdataframe(TRAIN_DIR)

test = pd.DataFrame()
test['image_paths'], test['labels'] = createdataframe(TEST_DIR)

# Image Preprocessing
def extract_features(image_paths):
    features = []
    for image_path in tqdm(image_paths):
        img = load_img(image_path, grayscale=True, target_size=(48, 48))
        img = np.array(img)
        features.append(img)
    features = np.array(features).reshape(len(features), 48, 48, 1)
    return features

x_train = extract_features(train['image_paths']) / 255.0
x_test = extract_features(test['image_paths']) / 255.0

# Encode Labels and One-hot
le = LabelEncoder()
y_train = to_categorical(le.fit_transform(train['labels']))
y_test = to_categorical(le.transform(test['labels']))

# Data Augmentation
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True
)
datagen.fit(x_train)

# Callbacks
early = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)
checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)

# Model Architecture
model = Sequential()

model.add(Conv2D(128, (3,3), activation='relu', input_shape=(48,48,1)))
model.add(BatchNormalization())
model.add(MaxPooling2D((2,2)))
model.add(Dropout(0.25))

model.add(Conv2D(256, (3,3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D((2,2)))
model.add(Dropout(0.25))

model.add(Conv2D(512, (3,3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D((2,2)))
model.add(Dropout(0.30))

model.add(Conv2D(512, (3,3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D((2,2)))
model.add(Dropout(0.30))

model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.40))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.30))
model.add(Dense(7, activation='softmax'))

# Compile
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train
history = model.fit(
    datagen.flow(x_train, y_train, batch_size=64),
    epochs=100,
    validation_data=(x_test, y_test),
    callbacks=[early, reduce_lr, checkpoint]
)

from google.colab import drive
from keras.models import load_model

# Step 1: Mount Google Drive
drive.mount('/content/drive')

# Step 2: Save model in both formats (choose one or both)

# Option A: Save as HDF5 (.h5)
model.save('/content/drive/MyDrive/emotion_model.h5')

# Option B: Save in TensorFlow SavedModel format
model.save('/content/drive/MyDrive/emotion_model.keras')

# (Optional) To load later:
# model = load_model('/content/drive/MyDrive/emotion_model.h5')
# OR
# model = load_model('/content/drive/MyDrive/emotion_model.keras')